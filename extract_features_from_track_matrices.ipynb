{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microtuble Analysis Project - Track Feature Extraction\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pims\n",
    "from skimage import io\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.color import label2rgb\n",
    "from skimage.util import random_noise\n",
    "import trackpy as tp\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "from numpy import linalg as LA\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import pickle\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "import math\n",
    "from track_analysis_functions_v1 import *\n",
    "from PIL import Image\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Folders to Analyze\n",
    "folders = glob.glob('./example_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#PHASE 1\n",
    "for folder in folders:\n",
    "    # Load all track data\n",
    "    #root_dir = directory + folder + \"/\"\n",
    "    root_dir = folder + \"/\"\n",
    "    track_dir = root_dir + \"track_matrices\"\n",
    "    mask_dir = root_dir + \"masks\"\n",
    "    pickle_dir = root_dir + \"pickle_objs/\"\n",
    "\n",
    "    file_names = os.listdir(track_dir)\n",
    "\n",
    "    try:\n",
    "        file_names.remove('.DS_Store')\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    label_imgs = []\n",
    "    mask_imgs = []\n",
    "    movie_names = []\n",
    "    t0_tracks = []\n",
    "    frame_lengths = []\n",
    "    print(\"Loading data: \" + folder)\n",
    "\n",
    "    img_id = 0\n",
    "    for name in file_names:\n",
    "        new_name = name.split(\".csv\")[0]\n",
    "        movie_names.append(name)\n",
    "        im = Image.open(mask_dir+\"/\"+new_name+\".tif\")\n",
    "        img_mask = np.array(im)\n",
    "        if img_mask[0,0] > 0:\n",
    "            img_mask = ~img_mask\n",
    "        #img_mask = io.imread(mask_dir+\"/\"+new_name+\".tif\", as_gray=True)\n",
    "        mask_imgs.append(img_mask)\n",
    "        label_imgs.append(label(img_mask, background=0))\n",
    "        #Loading Track Data as dataframes\n",
    "        t = pd.read_csv(track_dir+\"/\"+new_name+\".csv\", header=None)\n",
    "        t.columns = [\"x\", \"y\", \"mass\", \"frame\", \"particle\"]\n",
    "        t['img_id'] = img_id\n",
    "        t0_tracks.append(t)\n",
    "        frame_lengths.append(np.max(t['frame']))\n",
    "        img_id+=1\n",
    "\n",
    "    pickle.dump(file_names, open(pickle_dir + \"file_names.p\", \"wb\"))\n",
    "    \n",
    "    ##################################################\n",
    "    print(\"\\tt1_tracks: removing tracks less than a certain length\")\n",
    "    t1_tracks = []\n",
    "    for i,temp_df in enumerate(t0_tracks):\n",
    "        run_length = 3\n",
    "        if frame_lengths[i] >40:\n",
    "            run_length = 5\n",
    "        t1 = tp.filter_stubs(temp_df, run_length)\n",
    "        t1_tracks.append(t1) \n",
    "\n",
    "    ##################################################\n",
    "    print(\"\\tt2_tracks: identify the cell for each track\")\n",
    "    t2_tracks = []\n",
    "\n",
    "    for i,temp_df in enumerate(t1_tracks):\n",
    "        #print(\"Identifying Cells for Track\" , i)\n",
    "        t2 = identifyCellFromTrack(t1_tracks[i], label_imgs[i])\n",
    "        print(i, len(t2))\n",
    "        t2_tracks.append(t2) \n",
    "    pickle.dump(t2_tracks, open(pickle_dir + \"t2_tracks.p\", \"wb\"))\n",
    "    \n",
    "    t2_tracks= pickle.load(open(pickle_dir + \"t2_tracks.p\", \"rb\"))\n",
    "    res_framerate_file = root_dir + \"external_data/image_resolution_framerate.csv\"\n",
    "    res_framerate = pd.read_csv(res_framerate_file, header=None)\n",
    "\n",
    "    t2_2_tracks = []\n",
    "    for i,temp_df in enumerate(t2_tracks):\n",
    "        print(file_names[i])\n",
    "        row_val = res_framerate.loc[res_framerate[0] == file_names[i]]\n",
    "        new_df = pd.concat([temp_df, \n",
    "                        pd.DataFrame(columns=['new_x', 'new_y','new_frame', 'delta_t', 'resolution'])])\n",
    "        res = list(row_val[1])[0]\n",
    "        framerate = list(row_val[2])[0]\n",
    "        new_x = np.divide(temp_df['x'], res)\n",
    "        new_y = np.divide(temp_df['y'], res)\n",
    "        new_frame = np.multiply(temp_df['frame'], framerate)\n",
    "        new_df['new_x'] = new_x\n",
    "        new_df['new_y'] = new_y\n",
    "        new_df['new_frame'] = new_frame\n",
    "        new_df['delta_t'] = framerate\n",
    "        new_df['resolution'] = res\n",
    "        t2_2_tracks.append(new_df)\n",
    "\n",
    "    t2_tracks = t2_2_tracks\n",
    "    pickle.dump(t2_tracks, open(pickle_dir + \"t2_tracks.p\", \"wb\"))\n",
    "\n",
    "    ##################################################\n",
    "    print(\"\\tt2_features: Computing Motion and mass features from each track\")   \n",
    "    t2_features = []\n",
    "    for i,temp_df in enumerate(t2_tracks):\n",
    "        #print(\"Calculating Basic Features for Track\", i)\n",
    "        t2_feat = generate_features_df(temp_df)\n",
    "        t2_feat = calc_mass_features(temp_df, t2_feat)\n",
    "        t2_feat = calc_motion_features(temp_df, t2_feat)\n",
    "        t2_features.append(t2_feat)\n",
    "        \n",
    "    pickle.dump(t2_features, open(pickle_dir + \"t2_features.p\", \"wb\"))\n",
    "    \n",
    "    #t2_tracks = pickle.load(open(pickle_dir + \"t2_tracks.p\", \"rb\"))\n",
    "    #t2_features = pickle.load(open(pickle_dir + \"t2_features.p\", \"rb\"))\n",
    "    \n",
    "    ##################################################\n",
    "    print(\"\\tt3_tracks and t3_features: filtering tracks based on features values\")\n",
    "    t3_tracks = []\n",
    "    t3_features = []\n",
    "    for i,temp_df in enumerate(t2_tracks):\n",
    "        #print(\"Filtering based on Features for Track\", i)\n",
    "        t3 = temp_df\n",
    "        t3_feat = t2_features[i]\n",
    "        t3 = filter_track_from_feat(t3, t3_feat, 'new_displacement', min_val=0.5)\n",
    "        t3_feat = filter_traj_from_feat(t3_feat, 'new_displacement', min_val=0.5)\n",
    "\n",
    "        t3 = filter_track_from_feat(t3, t3_feat, 'new_persistance', min_val=0.6)\n",
    "        t3_feat = filter_traj_from_feat(t3_feat, 'new_persistance', min_val=0.6)\n",
    "        #t3 = filter_track_from_feat(t3, t3_feat, 'curvature', max_val = 0.5)\n",
    "        #t3_feat = filter_traj_from_feat(t3_feat, 'curvature', max_val = 0.5)\n",
    "\n",
    "        t3_tracks.append(t3)\n",
    "        t3_features.append(t3_feat)\n",
    "\n",
    "    pickle.dump(t3_tracks, open(pickle_dir + \"t3_tracks.p\", \"wb\"))\n",
    "    pickle.dump(t3_features, open(pickle_dir + \"t3_features.p\", \"wb\"))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PHASE 2\n",
    "for folder in folders:\n",
    "    ##################################################\n",
    "    # Load all track data\n",
    "    #root_dir = directory + folder + \"/\"\n",
    "    root_dir = folder + \"/\"\n",
    "    track_dir = root_dir + \"track_matrices\"\n",
    "    mask_dir = root_dir + \"masks\"\n",
    "    pickle_dir = root_dir + \"pickle_objs/\"\n",
    "\n",
    "    file_names = pickle.load(open(pickle_dir + \"file_names.p\", \"rb\"))\n",
    "    \n",
    "    img_sequences = []\n",
    "    label_imgs = []\n",
    "    mask_imgs = []\n",
    "    t0_tracks = []\n",
    "    \n",
    "    print(\"Loading data: \" + folder)\n",
    "    img_id = 0\n",
    "    for name in file_names:\n",
    "        new_name = name.split(\".csv\")[0]\n",
    "        try:\n",
    "            #Loading Mask Data\n",
    "            im = Image.open(mask_dir+\"/\"+new_name+\".tif\")\n",
    "            img_mask = np.array(im)\n",
    "            if img_mask[0,0] > 0:\n",
    "                img_mask = ~img_mask\n",
    "            #img_mask = io.imread(mask_dir+\"/\"+new_name+\".tif\", as_gray=True)\n",
    "            mask_imgs.append(img_mask)\n",
    "            label_imgs.append(label(img_mask))\n",
    "            #img_mask = io.imread(mask_dir+\"/\"+new_name+\".tif\")\n",
    "            #mask_imgs.append(img_mask)\n",
    "            #label_imgs.append(label(img_mask))\n",
    "            #Loading Track Data as dataframes\n",
    "            t = pd.read_csv(track_dir+\"/\"+new_name+\".csv\", header=None)\n",
    "            t.columns = [\"x\", \"y\", \"mass\", \"frame\", \"particle\"]\n",
    "            t['img_id'] = img_id\n",
    "            t0_tracks.append(t)\n",
    "            img_id+=1\n",
    "        except:\n",
    "            print(new_name + \" was not found\")\n",
    "    \n",
    "    ##################################################\n",
    "    print(\"\\tt3_tracks_updated: Calculating Distance Feature\")\n",
    "    t3_tracks = pickle.load(open(pickle_dir + \"t3_tracks.p\", \"rb\"))\n",
    "    t3_features = pickle.load(open(pickle_dir + \"t3_features.p\", \"rb\"))\n",
    "    \n",
    "    #Computing edge distance\n",
    "    distance_transforms = []\n",
    "    for i,temp in enumerate(t3_tracks):\n",
    "        num_cells = len(np.unique(label_imgs[i])) - 1\n",
    "        new_dist_transform = []\n",
    "        for j in range(num_cells):\n",
    "            cell_id = j+1\n",
    "            temp_mask = np.multiply(mask_imgs[i],label_imgs[i] == cell_id)\n",
    "            dist_transf= distance_transform_edt(temp_mask)\n",
    "            distance_transf_sum = np.sum(dist_transf)\n",
    "            num_pixels = np.sum(temp_mask)\n",
    "            if cell_id == 1:\n",
    "                new_dist_transform = np.divide(dist_transf, (distance_transf_sum/num_pixels))\n",
    "            else:\n",
    "                new_dist_transform = np.add(new_dist_transform, np.divide(dist_transf, (distance_transf_sum/num_pixels)))\n",
    "        distance_transforms.append(new_dist_transform)\n",
    "    \n",
    "    t3_temp_features = []\n",
    "    for i,temp_df in enumerate(t3_tracks):\n",
    "        unique_tracks = np.array(temp_df['particle'].unique())\n",
    "        new_df = pd.concat([t3_features[i],pd.DataFrame(columns=['edge_distance'])])\n",
    "        for index, track_id in enumerate(unique_tracks):\n",
    "            track_particles = temp_df.loc[temp_df['particle'] == track_id]\n",
    "            #x and y coordinates are switched in distance trasnform for some reason\n",
    "            x_vals = np.mean(track_particles['x'])\n",
    "            y_vals = np.mean(track_particles['y'])\n",
    "            result = distance_transforms[i][int(y_vals),int(x_vals)]   \n",
    "            new_df.loc[track_id]['edge_distance'] = result\n",
    "        t3_temp_features.append(new_df)\n",
    "    t3_features = t3_temp_features\n",
    "    \n",
    "    #Min axis distance and Maj axis distance features\n",
    "    majaxis_transform = []\n",
    "    minaxis_transform = []\n",
    "    for i,temp in enumerate(t3_tracks):\n",
    "        num_cells = len(np.unique(label_imgs[i])) - 1\n",
    "        new_maj_transform = np.zeros((mask_imgs[i].shape[0],mask_imgs[i].shape[1]))\n",
    "        new_min_transform = np.zeros((mask_imgs[i].shape[0],mask_imgs[i].shape[1]))\n",
    "        for j in range(num_cells):\n",
    "            cell_id = j+1\n",
    "            temp_mask = np.multiply(mask_imgs[i],label_imgs[i] == cell_id)\n",
    "\n",
    "            props = regionprops(temp_mask)\n",
    "            props = props[0]\n",
    "            y0, x0 = props.centroid\n",
    "            orientation = props.orientation\n",
    "            x1_maj = x0 + math.cos(orientation) * 0.5 * props.major_axis_length\n",
    "            y1_maj = y0 - math.sin(orientation) * 0.5 * props.major_axis_length\n",
    "            x2_maj = x0 - math.cos(orientation) * 0.5 * props.major_axis_length\n",
    "            y2_maj = y0 + math.sin(orientation) * 0.5 * props.major_axis_length\n",
    "\n",
    "            x1_min = x0 - math.sin(orientation) * 0.5 * props.minor_axis_length\n",
    "            y1_min = y0 - math.cos(orientation) * 0.5 * props.minor_axis_length\n",
    "            x2_min = x0 + math.sin(orientation) * 0.5 * props.minor_axis_length\n",
    "            y2_min = y0 + math.cos(orientation) * 0.5 * props.minor_axis_length\n",
    "\n",
    "            new_mask_min = np.zeros((temp_mask.shape[0], temp_mask.shape[1]))\n",
    "            new_mask_maj = np.zeros((temp_mask.shape[0], temp_mask.shape[1]))\n",
    "\n",
    "            for x_pos in range(temp_mask.shape[0]):\n",
    "                for y_pos in range(temp_mask.shape[1]):\n",
    "                    new_mask_min[x_pos,y_pos] = dist(x1_min,y1_min,x2_min,y2_min,y_pos,x_pos)\n",
    "                    new_mask_maj[x_pos,y_pos] = dist(x1_maj,y1_maj,x2_maj,y2_maj,y_pos,x_pos)\n",
    "\n",
    "            new_mask_min = np.multiply(temp_mask,new_mask_min)\n",
    "            max_value = np.max(new_mask_min)\n",
    "            new_mask_min = np.divide(new_mask_min, max_value)\n",
    "\n",
    "            new_mask_maj = np.multiply(temp_mask,new_mask_maj)\n",
    "            max_value = np.max(new_mask_maj)\n",
    "            new_mask_maj = np.divide(new_mask_maj, max_value)\n",
    "\n",
    "            new_maj_transform = np.add(new_mask_maj, new_maj_transform)\n",
    "            new_min_transform = np.add(new_mask_min, new_min_transform)\n",
    "\n",
    "        majaxis_transform.append(new_maj_transform)\n",
    "        minaxis_transform.append(new_min_transform)\n",
    "        t3_temp_features = []\n",
    "        \n",
    "    for i,temp_df in enumerate(t3_tracks):\n",
    "        unique_tracks = np.array(temp_df['particle'].unique())\n",
    "        new_df = pd.concat([t3_features[i],pd.DataFrame(columns=['maj_axis_distance', 'min_axis_distance'])])\n",
    "        for index, track_id in enumerate(unique_tracks):\n",
    "            track_particles = temp_df.loc[temp_df['particle'] == track_id]\n",
    "            #x and y coordinates are switched in distance trasnform for some reason\n",
    "            x_vals = np.mean(track_particles['x'])\n",
    "            y_vals = np.mean(track_particles['y'])\n",
    "            result_major = majaxis_transform[i][int(y_vals),int(x_vals)]   \n",
    "            result_minor = minaxis_transform[i][int(y_vals),int(x_vals)]   \n",
    "            new_df.loc[track_id]['maj_axis_distance'] = result_major\n",
    "            new_df.loc[track_id]['min_axis_distance'] = result_minor\n",
    "        t3_temp_features.append(new_df)\n",
    "    t3_features = t3_temp_features\n",
    "    \n",
    "    pickle.dump(t3_tracks, open(pickle_dir + \"t3_tracks.p\", \"wb\"))\n",
    "    pickle.dump(t3_features, open(pickle_dir + \"t3_features.p\", \"wb\"))\n",
    "\n",
    "    ##################################################\n",
    "    #t3_tracks = pickle.load(open(pickle_dir + \"t3_tracks.p\", \"rb\"))\n",
    "    #t3_features = pickle.load(open(pickle_dir + \"t3_features.p\", \"rb\"))\n",
    "    \n",
    "    print(\"\\tcreating track dictionaries\")\n",
    "    track_distance_dicts = {}\n",
    "\n",
    "    for i,temp_df in enumerate(t3_tracks):\n",
    "        print(i)\n",
    "        track_distance_dicts[i] = {}\n",
    "        unique_cells =  np.array(temp_df['cell_id'].unique())\n",
    "\n",
    "        for cell in unique_cells:\n",
    "            #track_distance_dicts[i][cell] = {}\n",
    "            #print(\"Creating Dictionary for Cell\", cell, \"in Image\", i)\n",
    "            temp_cell_df = temp_df.loc[temp_df['cell_id'] == cell]\n",
    "            unique_tracks = np.array(temp_cell_df['particle'].unique())\n",
    "            dist_mat = create_distance_matrix(temp_cell_df, unique_tracks)\n",
    "\n",
    "            for index,track_id in enumerate(unique_tracks):\n",
    "                #track_distance_dicts[i][cell][track_id] = {}\n",
    "                track_distance_dicts[i][track_id] = {}\n",
    "\n",
    "                for srange in [20,200, 5000]:\n",
    "                    nearby_tracks = [unique_tracks[j] for j, val in enumerate(dist_mat[index,:]) \n",
    "                                     if (val<srange and j != index)]\n",
    "                    #track_distance_dicts[i][cell][track_id][srange] = nearby_tracks\n",
    "                    track_distance_dicts[i][track_id][srange] = nearby_tracks  \n",
    "                    \n",
    "    pickle.dump(track_distance_dicts, open(pickle_dir + \"track_distance_dicts.p\", \"wb\"))\n",
    "    \n",
    "    #t3_tracks = pickle.load(open(pickle_dir + \"t3_tracks.p\", \"rb\"))\n",
    "    #t3_features = pickle.load(open(pickle_dir + \"t3_features.p\", \"rb\"))\n",
    "\n",
    "    #track_distance_dicts = pickle.load(open(pickle_dir + \"track_distance_dicts.p\", \"rb\"))\n",
    "    \n",
    "    ##################################################\n",
    "    # Get Features from Plots Above that Represent Orientation\n",
    "    print(\"\\tt4_features - Get similarity features\")\n",
    "    t4_features = []\n",
    "    for i,temp_df in enumerate(t3_tracks):\n",
    "        print(i)\n",
    "        #print(\"Computing Similarity Features for Image\",  i)\n",
    "        unique_tracks = np.array(temp_df['particle'].unique())\n",
    "        new_df = pd.concat([t3_features[i],pd.DataFrame(columns=['similarity_20', 'similarity_200', 'similarity_5000'])])\n",
    "        for index, track_id in enumerate(unique_tracks):\n",
    "            #nearby_tracks = track_distance_dicts[i][track_id][5]\n",
    "            #if nearby_tracks == []:\n",
    "            #    continue\n",
    "            #else:\n",
    "            #    distances = compute_cosine_distance(temp_df, track_id, nearby_tracks)\n",
    "            #    average_distance = np.average(np.array(distances)[:,0])\n",
    "            #    new_df.loc[track_id]['similarity_5'] = average_distance\n",
    "\n",
    "            #nearby_tracks = track_distance_dicts[i][track_id][10]\n",
    "            #distances = compute_cosine_distance(temp_df, track_id, nearby_tracks)\n",
    "            #average_distance = np.average(np.array(distances)[:,0])\n",
    "            #new_df.loc[track_id]['similarity_10'] = average_distance\n",
    "\n",
    "            nearby_tracks = track_distance_dicts[i][track_id][20]\n",
    "            if nearby_tracks == []:\n",
    "                continue\n",
    "            distances = compute_cosine_distance(temp_df, track_id, nearby_tracks)\n",
    "            average_distance = np.average(np.array(distances)[:,0])\n",
    "            new_df.at[track_id, 'similarity_20'] = -1\n",
    "            new_df.at[track_id, 'similarity_20'] = average_distance\n",
    "\n",
    "            #nearby_tracks = track_distance_dicts[i][track_id][100]\n",
    "            #distances = compute_cosine_distance(temp_df, track_id, nearby_tracks)\n",
    "            #average_distance = np.average(np.array(distances)[:,0])\n",
    "            #new_df.loc[track_id]['similarity_100'] = average_distance\n",
    "\n",
    "            nearby_tracks = track_distance_dicts[i][track_id][200]\n",
    "            distances = compute_cosine_distance(temp_df, track_id, nearby_tracks)\n",
    "            average_distance = np.average(np.array(distances)[:,0])\n",
    "            new_df.at[track_id, 'similarity_200'] = average_distance\n",
    "            \n",
    "            nearby_tracks = track_distance_dicts[i][track_id][5000]\n",
    "            distances = compute_cosine_distance(temp_df, track_id, nearby_tracks)\n",
    "            average_distance = np.average(np.array(distances)[:,0])\n",
    "            new_df.at[ track_id, 'similarity_5000'] = average_distance\n",
    "            \n",
    "        t4_features.append(new_df)\n",
    "        \n",
    "    pickle.dump(t4_features, open(pickle_dir + \"t4_features.p\", \"wb\"))\n",
    "    \n",
    "    t4_features = pickle.load(open(pickle_dir + \"t4_features.p\", \"rb\"))\n",
    "    \n",
    "    ##################################################\n",
    "    print(\"\\tt5_features - Get Orientation Features\")\n",
    "    t5_features = []\n",
    "    for i,temp_df in enumerate(t3_tracks):\n",
    "        #print(\"Computing Major/Minor Axis Features for Image\",  i)\n",
    "        unique_tracks = np.array(temp_df['particle'].unique())\n",
    "        new_df = pd.concat([t4_features[i],pd.DataFrame(columns=['maj_orient', 'min_orient', 'maj_orient_mag', 'min_orient_mag'])])\n",
    "        for index, track_id in enumerate(unique_tracks):\n",
    "            cell_ID = int(temp_df.loc[temp_df['particle']==track_id]['cell_id'].unique()[0])\n",
    "            distance_maj = getOrientationFromAxis(temp_df, track_id, cell_ID=cell_ID, label_img=label_imgs[i], axis='major')\n",
    "            distance_min = getOrientationFromAxis(temp_df, track_id, cell_ID=cell_ID, label_img=label_imgs[i], axis='minor')\n",
    "            \n",
    "            #For some reason the major and minor orientation got switched for images:\n",
    "            #M40 0836 comet HT1080 left ear 2020 02 21\", \"M41 0836 comer Ht1080 rightear 2020 02 21\", \n",
    "            #\"M42 0836 comet Ht1080 no ear 2020 02 25 treated\n",
    "            '''\n",
    "            new_df.at[track_id,'maj_orient'] = distance_maj\n",
    "            new_df.at[track_id,'min_orient'] = distance_min\n",
    "            new_df.at[track_id,'maj_orient_mag'] = np.absolute(distance_maj)\n",
    "            new_df.at[track_id,'min_orient_mag'] = np.absolute(distance_min)\n",
    "            '''\n",
    "            new_df.at[track_id,'min_orient'] = distance_maj\n",
    "            new_df.at[track_id,'maj_orient'] = distance_min\n",
    "            new_df.at[track_id,'min_orient_mag'] = np.absolute(distance_maj)\n",
    "            new_df.at[track_id,'maj_orient_mag'] = np.absolute(distance_min)\n",
    "\n",
    "\n",
    "        t5_features.append(new_df)\n",
    " \n",
    "    ##################################################\n",
    "    print(\"\\tt6_features - Creating Cell IDs\")\n",
    "    t6_features = []\n",
    "    for i,temp_df in enumerate(t3_tracks):\n",
    "        #print(\"Creating Unique Cell ID for image\",  i)\n",
    "        unique_tracks = np.array(temp_df['particle'].unique())\n",
    "        new_df = pd.concat([t5_features[i],pd.DataFrame(columns=['unique_cell_id', 'unique_id', 'img_id'])])\n",
    "        for index, track_id in enumerate(unique_tracks):\n",
    "            cell_ID = int(temp_df.loc[temp_df['particle']==track_id]['cell_id'].unique()[0])\n",
    "            new_cell_id = float(str(i)+ '.'+str(cell_ID))\n",
    "            new_df.at[track_id,'unique_cell_id'] = new_cell_id\n",
    "            new_part_id = float(str(i)+'.'+str(int(track_id)))\n",
    "            new_df.at[track_id,'unique_id'] = new_part_id\n",
    "            new_df.at[track_id,'img_id'] = i\n",
    "        t6_features.append(new_df.dropna())\n",
    "        \n",
    "    pickle.dump(t6_features, open(pickle_dir + \"t6_features.p\", \"wb\"))\n",
    "    #t6_features = pickle.load(open(pickle_dir + \"t6_features.p\", \"rb\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
